# Attention Mechansim 
### *- Implementation of Baudanau and Luong Attention using Pytorch -*

#### Dependency

```
pandas==1.4.4
numpy==1.22.4
```


#### Reference 

https://tutorials.pytorch.kr/intermediate/seq2seq_translation_tutorial.html

https://github.com/rawmarshmellows/pytorch-batch-luong-attention

https://github.com/Huffon/pytorch-transformer-kor-eng
